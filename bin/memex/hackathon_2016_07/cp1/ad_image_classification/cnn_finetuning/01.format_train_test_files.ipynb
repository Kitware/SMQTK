{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Train/Test split files for Caffe\n",
    "\n",
    "Need to create two files, train.txt and text.txt, that list out the image files for each set and their 0/1 labels (0 == negative, 1 == positive).  In our case, positive means \"relevant for HT investigation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mapping of SHA1 value to the path of the original image file\n",
    "sha2path = dict((r[1],r[0]) for r in csv.reader(open('../positive.cmd.processed.csv')))\n",
    "sha2path.update(dict((r[1],r[0]) for r in csv.reader(open('../negative.cmd.processed.csv'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use train-1/2/3 set of images to train-test the network. Split 3-1 (train - test)\n",
    "train1_pos_shas = cPickle.load(open('../train1_pos_shas.pickle'))\n",
    "train2_pos_shas = cPickle.load(open('../train2_pos_shas.pickle'))\n",
    "train3_pos_shas = cPickle.load(open('../train3_pos_shas.pickle'))\n",
    "test_pos_shas   = cPickle.load(open('../test_pos_shas.pickle'))\n",
    "train1_neg_shas = cPickle.load(open('../train1_neg_shas.pickle'))\n",
    "train2_neg_shas = cPickle.load(open('../train2_neg_shas.pickle'))\n",
    "train3_neg_shas = cPickle.load(open('../train3_neg_shas.pickle'))\n",
    "test_neg_shas   = cPickle.load(open('../test_neg_shas.pickle'))\n",
    "\n",
    "train_pos_shas = train1_pos_shas | train2_pos_shas | train3_pos_shas\n",
    "train_neg_shas = train1_neg_shas | train2_neg_shas | train3_neg_shas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For each sha, find where it exists between the two download directories:\n",
    "#   /home/purg/data/memex/ht/hackathon_201607_cp1/training_positives/data/CP1_imageset/\n",
    "#   /home/purg/data/memex/ht/dan_bootystor/images/\n",
    "import os\n",
    "\n",
    "def find_sha1_filepath(sha1):\n",
    "    pre = sha1[:3]\n",
    "    t1 = os.path.join(\n",
    "        '/home/purg/data/memex/ht/hackathon_201607_cp1/training_positives/data/CP1_imageset',\n",
    "        pre, sha1)\n",
    "    t2 = os.path.join(\n",
    "        '/home/purg/data/memex/ht/dan_bootystor/images',\n",
    "        pre, sha1)\n",
    "    if os.path.isfile(t1):\n",
    "        return t1\n",
    "    elif os.path.isfile(t2):\n",
    "        return t2\n",
    "    else:\n",
    "        raise ValueError(\"No path for sha: %s\" % sha1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remember:\n",
    "#   0 == negative\n",
    "#   1 == positive\n",
    "with open('train.image_truth.txt', 'w') as f:\n",
    "    for sha in train_pos_shas:\n",
    "        fp = find_sha1_filepath(sha)\n",
    "        f.write(fp + ' 1\\n')\n",
    "    for sha in train_neg_shas:\n",
    "        fp = find_sha1_filepath(sha)\n",
    "        f.write(fp + ' 0\\n')\n",
    "\n",
    "with open('test.image_truth.txt', 'w') as f:\n",
    "    for sha in test_pos_shas:\n",
    "        fp = find_sha1_filepath(sha)\n",
    "        f.write(fp + ' 1\\n')\n",
    "    for sha in test_neg_shas:\n",
    "        fp = find_sha1_filepath(sha)\n",
    "        f.write(fp + ' 0\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Output test and train sets with equal balance, randomly sub-sampling where needed\n",
    "even_train_size = min([len(train_pos_shas), len(train_neg_shas)])\n",
    "even_test_size = min([len(test_pos_shas), len(test_neg_shas)])\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "even_train_pos = random.sample(train_pos_shas, even_train_size)\n",
    "even_train_neg = random.sample(train_neg_shas, even_train_size)\n",
    "even_test_pos = random.sample(test_pos_shas, even_test_size)\n",
    "even_test_neg = random.sample(test_neg_shas, even_test_size)\n",
    "\n",
    "with open('train.image_truth.even.txt', 'w') as f:\n",
    "    for sha in even_train_pos:\n",
    "        fp = find_sha1_filepath(sha)\n",
    "        f.write(fp + ' 1\\n')\n",
    "    for sha in even_train_neg:\n",
    "        fp = find_sha1_filepath(sha)\n",
    "        f.write(fp + ' 0\\n')\n",
    "\n",
    "with open('test.image_truth.even.txt', 'w') as f:\n",
    "    for sha in even_test_pos:\n",
    "        fp = find_sha1_filepath(sha)\n",
    "        f.write(fp + ' 1\\n')\n",
    "    for sha in even_test_neg:\n",
    "        fp = find_sha1_filepath(sha)\n",
    "        f.write(fp + ' 0\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Caffe training\n",
    "\n",
    "To start model fine-tuning:\n",
    "\n",
    "    /home/purg/dev/caffe/build-master/tools/caffe train -sigint_effect snapshot -solver solver.prototxt -weights <base_model>\n",
    "    \n",
    "If already started and resuming from a snapshot is desired:\n",
    "\n",
    "    /home/purg/dev/caffe/build-master/tools/caffe train -sigint_effect snapshot -solver solver.prototxt -snapshot <snapshot_file>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
